\documentclass[a4paper, 11pt, twoside, openany, onecolumn, final]{memoir}

\usepackage{style}

\title{\tb{Inteligencia artificial: Práctica $8$}}
\author{Álvaro García Tenorio \thanks{\texttt{\url{alvgar14@ucm.es}}}\and Miguel Pascual Domínguez\thanks{\texttt{\url{miguepas@ucm.es}}}}
\date{\today}

\begin{document}
	\maketitle
	\tableofcontents
	\chapter{Agrupamiento}
	\section{Descripción del conjunto}
	Para este experimento hemos seleccionado un conjunto de datos llamado ausencias de trabajo. Los datos pertenecen a un estudio académico realizado por la universidad Nove de Julho de Brasil, por dos estudiantes y un profesor, durante tres años desde 2007 hasta 2010 en una empresa brasileña.
	Los datos, los hemos obtenido de la siguiente pagina, \url{http://archive.ics.uci.edu/ml/datasets/Absenteeism+at+work}.
	
	Expliquemos ahora los atributos/variables de este conjunto de datos:
	
	\begin{enumerate}
\item  ID (Identificador): variable formada por un conjunto de números del 1 al 36 que consisten en 36 identificadores de 36 personas distintas.
\item Motivo de la ausencia: catalogado en 28 números que cada uno corresponde con un motivo de incidencia, los 21 primeros se tratan de las primeras 21 enfermedades del código internacional de enfermedades (ICD) y los 7 ultimos, corresponden con 7 motivos no incluidos en el ICD, que son el acompañamiento de otro paciente (22), una consulta médica (23), donación de sangre (24), análisis médico (25), ausencia injustificada (26), fisioterapia (27) y dentista (28).
\item Mes de ausencia: número real que corresponde con el mes de la ausencia del 1 al 12.
\item Día laboral de la semana: lunes (2), martes (3), miércoles (4), jueves (5) y viernes (6). 
\item Estación del año: verano (1), otoño (2), invierno (3) y primavera (4).
\item Gasto de transporte: número real.
\item Distancia desde casa hasta la oficina (km): número real.
\item Tiempo de trabajo: número entero.
\item Edad: número entero
\item Media de carga de trabajo: número real.
\item Porcentaje de cumplimento de trabajos: número real entre 0.0 y 100.0.
\item Incidencia disciplinaria: Si (1) y No (0).
\item Educación: número real, catalogado de la siguiente manera; bachillerato (1), graduado (2), posgraduado (3) y master y docotorado (4).
\item Número de hijos: número real.
\item Bebedor social: Si (1) y No (0).
\item Fumador social: Si (1) y No (0).
\item Número de mascotas: número real.
\item Peso: número real.
\item Altura: número real.
\item Índice de masa corporal: número real.
\item Tiempo de ausencia en horas: número real.
\end{enumerate}
	\section{Parametrización del algoritmo de agrupamiento}
	Veamos ahora como preparamos los datos y las variables para aplicar el algoritmo de agrupamiento jerárquico.
	
	Empecemos primero observando si tiene sentido o no estandarizar o normalizar o no hacerlas nada a las variables. Dado que algunas de ellas a pesar de que son números, realmente se les deberían considerar variables categóricas, por ejemplo el ID, el motivo de la ausencia, el día laboral, la estación del año, la incidencia disciplinaria, y el bebedor y fumador social; y por tanto al tener que considerarlas así, no tendría ningún sentido realizarles ajuste numérico.
	
	Fijemonos ahora en el resto de las variables,   AQUI FALTA DECIR PORQUE LAS OTRAS VARIABLES NO LAS ESTANDARIZAMOS NI NORMALIZAMOS PERO NO SE ARGUMENTAR PORQUE (PORQUE LA RAZON QUE SE ME OCURRE ES PURA "PEREZA").
	
	Decidamos ahora el número de clusters que queremos para nuestro agrupamiento, para ello tenemos que observar que dependiendo de que variable tomamos como principal, se necesitará un número o otro, por ejemplo si cogemos como variable, el día laboral, lo interesante sería tomar como número de clusters igual a 5, para observar como el algoritmo te agrupa por cada día laboral o por ejemplo por el motivo de la ausencia, o la estación del año, etc.
	Por todo esto, hemos decidido optar por 
	\section{Resultados}
	\section{Conclusiones y respuestas}
	\chapter{Clasificación}
		\section{Descripción del conjunto}
		Para este tipo de problema, lo interesante es coger un conjunto/database que tenga pocos atributos y muchas instancias, por ello el conjunto que hemos seleccionado es un dataset sobre una evaluación de coches, hemos obtenido los datos de la siguiente página \url{http://archive.ics.uci.edu/ml/datasets/Car+Evaluation}. Los archivos descargados no venían en formato .arff, por tanto hemos tenido que añadir parte del codigo de definición de atributos y de la relación, pero los datos no han sido modificados.
		
		Expliquemos ahora los atributos/variables, todos ellos categóricos, ninguno numérico; de este conjunto de datos:
	
	\begin{enumerate}
\item Compra: Precio de compra; muy alto (vhigh), alto (high), medio (med) y bajo (low).
\item Mantenimiento: Precio de mantenimiento; muy alto (vhigh), alto (high), medio (med) y bajo (low).
\item Puertas: Número de puertas clasificado en 4 categorías; 2, 3, 4 y 5 o más.
\item Personas: Número de personas clasificado en 3 categorías; 2, 4 y más.
\item Maletero: Capacidad del maletero; pequeña, media y grande.
\item Seguridad: baja, media y alta. 
\item Tipo de coche según aceptabilidad: inaceptable (unacc), aceptable (acc), bueno (good) y muy bueno (vgood). 
\end{enumerate}
		
		Una vez comentado los atributos, expliquemos el problema. 

Tal y como son los datos, hemos decidido que para aprovechar el potencial de los mismos, lo más lógico es plantear el problema de clasificar la aceptabilidad de los coches en función de los otros 6 atributos, ya que así podemos observar más adelante el poder del algunos atributos como la seguridad y el número de personas que ya clasifican una cantidad de los coches.

Mostramos aquí el histograma de la variable tipo de coche según aceptabilidad. 
	METER HISTOGRAMA COMO IMAGEN, LA OBTENEMOS DE WEKA. 
	\section{Parametrización del J48}
		Dado que todas nuestras variables son categóricas no se les puede normalizar (englobar los valores entre $0$ y $1$) ni estandarizar (modificar los datos para que tengan media $0$ y varianza $1$). 
		Primero se realizará una ejecución del algoritmo sin validación ni entrenamiento, después se realizará otra ejecución en validación y entrenamiento al $66\%$.
		
		En la primera ejecución se han mantenido los parámetros del algoritmo predeterminado por Weka y en la segunda ejecución...
	\section{Resultados}
	AQUÍ HAY QUE PONER LOS ÁRBOLES DE DECISIÓN, LAS IMAGENES, QUE HABRA QUE VER COMO SACARLAS DE WEKA Y METERLAS.
	\section{Conclusiones y respuestas}
	\chapter{Regresión}
		\section{Descripción del conjunto}
	\section{Parametrización del perceptrón multicapa}
	\section{Parametrización del K-NN}
	\section{Resultados}
	\section{Conclusiones}
\end{document}